# Testing Coverage Expansion - Implementation Guide

**Status:** ðŸš€ Ready to Execute
**Created:** 2025-11-17
**Parent Plan:** [TESTING-COVERAGE-EXPANSION-PLAN.md](./TESTING-COVERAGE-EXPANSION-PLAN.md)
**Priority:** CRITICAL - Zero coverage on main API endpoints

---

## Executive Summary

This guide provides **exact, copy-paste-ready code** for implementing the testing coverage expansion plan. Focus is on **quick wins** and **critical paths** that are currently untested.

### Current Coverage Analysis (As of 2025-11-17)

**âœ… EXCELLENT (Already at 98-100%):**
- `phentrieve/retrieval/dense_retriever.py` - **98%**
- `phentrieve/retrieval/output_formatters.py` - **100%**
- `phentrieve/retrieval/reranker.py` - **100%**

**âŒ CRITICAL GAPS (0% coverage on main API!):**
- `api/routers/query_router.py` - **0%** (63 statements) âš ï¸ **MOST CRITICAL!**
- `api/routers/similarity_router.py` - **0%** (67 statements)
- `api/routers/text_processing_router.py` - **0%** (145 statements)
- `api/routers/config_info_router.py` - **0%** (35 statements)

**âš ï¸ NEEDS IMPROVEMENT:**
- `phentrieve/retrieval/query_orchestrator.py` - **8%** (258/279 uncovered)
- `phentrieve/retrieval/text_attribution.py` - **14%** (31/36 uncovered)

### Quick Wins Strategy (Week 1)

```
Day 1 (4h): Setup tooling + shared fixtures
Day 2-3 (8h): Query Router tests (0% â†’ 90%) â† BIGGEST IMPACT
Day 4 (4h): Query Orchestrator tests (8% â†’ 70%)
Day 5 (4h): Similarity Router tests (0% â†’ 80%)
```

**Result:** Critical API endpoints fully tested in 1 week!

---

## Day 1: Setup & Foundation (4 hours)

### Task 1.1: Install flake8-pytest-style (15 min)

**Why:** Catches pytest anti-patterns automatically during linting.

**File:** `pyproject.toml`

Find the `[project.optional-dependencies]` section and add to `dev`:

```toml
[project.optional-dependencies]
dev = [
    # ... existing dependencies ...
    "flake8-pytest-style>=2.0.0",  # ADD THIS LINE
]
```

**Command:**
```bash
uv sync --extra dev
```

**Verify:**
```bash
flake8 --version | grep pytest-style
```

---

### Task 1.2: Add Makefile Target for Test Linting (10 min)

**File:** `Makefile`

Add after the existing `lint` target:

```makefile
.PHONY: lint-tests
lint-tests:  ## Lint tests for pytest anti-patterns
	@echo "Linting tests for pytest anti-patterns..."
	flake8 tests/ --select=PT --show-source --statistics
```

**Test it:**
```bash
make lint-tests
```

---

### Task 1.3: Create Enhanced Shared Fixtures (2 hours)

**File:** `tests/conftest.py` (REPLACE ENTIRE CONTENTS)

```python
"""Shared fixtures for all tests."""

from pathlib import Path
from typing import Any
from unittest.mock import MagicMock

import pytest


# =============================================================================
# DATA FIXTURES (DRY - used across all tests)
# =============================================================================


@pytest.fixture(scope="session")
def test_data_dir() -> Path:
    """Test data directory."""
    return Path(__file__).parent / "test_data"


@pytest.fixture
def sample_clinical_texts() -> list[str]:
    """Sample clinical texts for testing."""
    return [
        "Patient presents with seizures and developmental delay",
        "No evidence of heart disease",
        "Family history of autism spectrum disorder",
    ]


@pytest.fixture
def hpo_term_factory():
    """Factory for creating HPO term dictionaries with custom attributes.

    This follows DRY principle - create test data programmatically, not in files.

    Usage:
        def test_example(hpo_term_factory):
            term = hpo_term_factory(name="Custom Term")
            assert term["name"] == "Custom Term"
            assert term["id"] == "HP:0000001"  # Defaults preserved
    """
    def _create(**overrides: Any) -> dict[str, Any]:
        defaults = {
            "id": "HP:0000001",
            "name": "Seizure",
            "definition": "Abnormal excessive neuronal activity",
            "synonyms": ["Epileptic seizure"],
            "label": "Seizure",
        }
        return {**defaults, **overrides}
    return _create


@pytest.fixture
def hpo_query_result_factory():
    """Factory for creating mock query result dictionaries.

    Usage:
        def test_example(hpo_query_result_factory):
            result = hpo_query_result_factory(score=0.95)
            assert result["score"] == 0.95
    """
    def _create(**overrides: Any) -> dict[str, Any]:
        defaults = {
            "hpo_id": "HP:0000001",
            "label": "Seizure",
            "score": 0.85,
            "definition": "Abnormal excessive neuronal activity",
            "synonyms": ["Epileptic seizure"],
        }
        return {**defaults, **overrides}
    return _create


@pytest.fixture
def sample_query_request_data() -> dict[str, Any]:
    """Sample valid query request data for API tests."""
    return {
        "text": "Patient has seizures",
        "model_name": "FremyCompany/BioLORD-2023-M",
        "language": "en",
        "num_results": 10,
        "similarity_threshold": 0.3,
        "enable_reranker": False,
        "detect_query_assertion": True,
    }


# =============================================================================
# MOCK FIXTURES (Strategic mocking for unit tests)
# =============================================================================


@pytest.fixture
def mock_embedding_model(mocker):
    """Mock sentence transformer model.

    Returns deterministic 384-dimensional embeddings for testing.
    """
    mock = mocker.MagicMock()
    mock.encode.return_value = [[0.1] * 384]  # Mock 384-dim embedding
    mock.get_sentence_embedding_dimension.return_value = 384
    return mock


@pytest.fixture
def mock_chromadb_collection(mocker):
    """Mock ChromaDB collection with realistic query results."""
    mock = mocker.MagicMock()
    mock.query.return_value = {
        "ids": [["HP:0001250", "HP:0000729"]],
        "distances": [[0.15, 0.25]],
        "metadatas": [[
            {"label": "Seizure"},
            {"label": "Autistic behavior"},
        ]],
    }
    mock.count.return_value = 1000  # Mock collection size
    return mock


@pytest.fixture
def mock_dense_retriever(mocker, hpo_query_result_factory):
    """Mock DenseRetriever with realistic query method.

    Returns 2 HPO terms by default. Override in individual tests if needed.
    """
    mock = mocker.MagicMock()
    mock.model_name = "FremyCompany/BioLORD-2023-M"
    mock.query.return_value = [
        hpo_query_result_factory(hpo_id="HP:0001250", label="Seizure", score=0.85),
        hpo_query_result_factory(hpo_id="HP:0000729", label="Autistic behavior", score=0.72),
    ]
    return mock


@pytest.fixture
def mock_cross_encoder(mocker):
    """Mock cross-encoder for reranking tests."""
    mock = mocker.MagicMock()
    mock.predict.return_value = [0.95, 0.88]  # Mock reranker scores
    return mock


# =============================================================================
# API TEST FIXTURES (FastAPI TestClient)
# =============================================================================


@pytest.fixture
def mock_api_dependencies(mocker, mock_dense_retriever, mock_cross_encoder):
    """Mock all API dependencies for isolated endpoint testing.

    This allows testing API routes without loading real models or databases.

    Usage:
        def test_query_endpoint(client, mock_api_dependencies):
            response = client.post("/api/v1/query", json={...})
            # Test runs without loading real models!
    """
    # Mock the dependency functions
    mocker.patch(
        "api.dependencies.get_dense_retriever_dependency",
        return_value=mock_dense_retriever,
    )
    mocker.patch(
        "api.dependencies.get_cross_encoder_dependency",
        return_value=mock_cross_encoder,
    )

    # Mock execute_hpo_retrieval_for_api to avoid complex orchestration
    mock_results = {
        "results": [
            {
                "hpo_id": "HP:0001250",
                "label": "Seizure",
                "score": 0.85,
                "definition": "Abnormal excessive neuronal activity",
            }
        ],
        "original_query_assertion_status": "affirmative",
    }
    mocker.patch(
        "api.routers.query_router.execute_hpo_retrieval_for_api",
        return_value=mock_results,
    )

    return {
        "retriever": mock_dense_retriever,
        "cross_encoder": mock_cross_encoder,
        "results": mock_results,
    }


# =============================================================================
# INTEGRATION TEST FIXTURES (Real instances, no mocks)
# =============================================================================


@pytest.fixture
def temp_chroma_db(tmp_path):
    """Create a temporary ChromaDB instance for integration tests.

    This is a REAL ChromaDB, not a mock. Use for integration tests only.
    """
    import chromadb

    db_path = tmp_path / "test_chromadb"
    client = chromadb.PersistentClient(path=str(db_path))

    yield client

    # Cleanup happens automatically via tmp_path


@pytest.fixture
def temp_index_dir(tmp_path) -> Path:
    """Temporary directory for test index files."""
    index_dir = tmp_path / "indexes"
    index_dir.mkdir(parents=True, exist_ok=True)
    return index_dir
```

**Why these fixtures:**
1. âœ… **Factories** - Follow DRY principle (create data programmatically)
2. âœ… **Mocks** - Strategic mocking for unit tests (external dependencies only)
3. âœ… **Real instances** - For integration tests (temp ChromaDB)
4. âœ… **Reusable** - Used across all test files, avoiding duplication

---

### Task 1.4: Add Test-Specific conftest for API Tests (1 hour)

**File:** `tests/unit/api/conftest.py` (CREATE NEW FILE)

```python
"""API-specific test fixtures."""

import pytest
from fastapi.testclient import TestClient


@pytest.fixture
def client():
    """FastAPI TestClient for API endpoint testing.

    This creates a real TestClient but with mocked dependencies.
    Use mock_api_dependencies fixture to mock external services.

    Usage:
        def test_endpoint(client, mock_api_dependencies):
            response = client.post("/api/v1/query", json={...})
            assert response.status_code == 200
    """
    from api.main import app

    with TestClient(app) as test_client:
        yield test_client


@pytest.fixture
def valid_query_payload(sample_query_request_data):
    """Valid query request payload for POST /api/v1/query tests."""
    return sample_query_request_data


@pytest.fixture
def invalid_query_payloads():
    """Collection of invalid query payloads for error testing.

    Returns list of (payload, expected_error_substring) tuples.
    """
    return [
        ({"text": ""}, "text"),  # Empty text
        ({"text": "seizures", "num_results": -1}, "num_results"),  # Negative num
        ({"text": "seizures", "similarity_threshold": 1.5}, "threshold"),  # Invalid threshold
        ({}, "text"),  # Missing required field
    ]
```

---

## Day 2-3: Query Router Tests (CRITICAL - 0% â†’ 90%)

### Task 2.1: Create Query Router Test File (6 hours)

**File:** `tests/unit/api/test_query_router.py` (CREATE NEW FILE)

This is **241 statements** covering all critical paths. Read carefully and implement in full.

```python
"""Tests for API query router (CRITICAL PATH - Main API endpoint)."""

import pytest
from fastapi import HTTPException


class TestQueryRouterPOST:
    """Tests for POST /api/v1/query endpoint."""

    def test_query_with_valid_request_returns_200(
        self, client, mock_api_dependencies, valid_query_payload
    ):
        """Test successful query returns 200 with results."""
        response = client.post("/api/v1/query", json=valid_query_payload)

        assert response.status_code == 200
        data = response.json()

        # Verify response structure
        assert "query_text_received" in data
        assert "language_detected" in data
        assert "model_used_for_retrieval" in data
        assert "results" in data

        # Verify data values
        assert data["query_text_received"] == valid_query_payload["text"]
        assert data["model_used_for_retrieval"] == valid_query_payload["model_name"]
        assert isinstance(data["results"], list)
        assert len(data["results"]) > 0

    def test_query_with_minimal_payload_succeeds(self, client, mock_api_dependencies):
        """Test query with only required field (text) works."""
        minimal_payload = {"text": "Patient has seizures"}

        response = client.post("/api/v1/query", json=minimal_payload)

        assert response.status_code == 200
        data = response.json()
        assert data["query_text_received"] == "Patient has seizures"

    def test_query_without_text_returns_422(self, client):
        """Test query without required 'text' field returns validation error."""
        response = client.post("/api/v1/query", json={})

        assert response.status_code == 422
        error_data = response.json()
        assert "detail" in error_data

    @pytest.mark.parametrize("invalid_payload,error_field", [
        ({"text": ""}, "text"),
        ({"text": "query", "num_results": -1}, "num_results"),
        ({"text": "query", "similarity_threshold": 1.5}, "similarity_threshold"),
        ({"text": "query", "similarity_threshold": -0.1}, "similarity_threshold"),
    ])
    def test_query_with_invalid_params_returns_422(
        self, client, invalid_payload, error_field
    ):
        """Test query with invalid parameters returns validation error."""
        response = client.post("/api/v1/query", json=invalid_payload)

        assert response.status_code == 422
        error_data = response.json()
        # Check that error mentions the problematic field
        error_str = str(error_data)
        assert error_field in error_str.lower()

    def test_query_with_reranker_enabled_uses_cross_encoder(
        self, client, mock_api_dependencies, valid_query_payload
    ):
        """Test enabling reranker triggers cross-encoder dependency."""
        payload = {**valid_query_payload, "enable_reranker": True}

        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        data = response.json()
        assert data["reranker_used"] is not None

    def test_query_auto_detects_language_when_not_provided(
        self, client, mock_api_dependencies, mocker
    ):
        """Test language is auto-detected when not in request."""
        # Mock detect_language function
        mock_detect = mocker.patch(
            "api.routers.query_router.detect_language",
            return_value="en"
        )

        payload = {"text": "Patient has seizures"}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        assert mock_detect.called
        data = response.json()
        assert data["language_detected"] == "en"

    def test_query_uses_provided_language_without_detection(
        self, client, mock_api_dependencies, mocker
    ):
        """Test explicit language parameter skips auto-detection."""
        mock_detect = mocker.patch("api.routers.query_router.detect_language")

        payload = {"text": "Patient has seizures", "language": "de"}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        assert not mock_detect.called  # Should NOT detect if provided
        data = response.json()
        assert data["language_detected"] == "de"

    def test_query_with_custom_model_name_works(
        self, client, mock_api_dependencies
    ):
        """Test query with custom embedding model."""
        payload = {
            "text": "seizures",
            "model_name": "sentence-transformers/all-MiniLM-L6-v2"
        }

        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        data = response.json()
        assert data["model_used_for_retrieval"] == "sentence-transformers/all-MiniLM-L6-v2"

    def test_query_with_monolingual_reranker_mode(
        self, client, mock_api_dependencies
    ):
        """Test monolingual reranker mode."""
        payload = {
            "text": "seizures",
            "enable_reranker": True,
            "reranker_mode": "monolingual",
            "language": "de",
        }

        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200

    def test_query_respects_num_results_parameter(
        self, client, mock_api_dependencies, mocker
    ):
        """Test num_results parameter limits returned results."""
        # Override mock to return many results
        mock_retrieval = mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={
                "results": [{"hpo_id": f"HP:{i:07d}"} for i in range(50)],
                "original_query_assertion_status": "affirmative",
            }
        )

        payload = {"text": "seizures", "num_results": 5}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        # Verify execute was called with correct num_results
        call_kwargs = mock_retrieval.call_args.kwargs
        assert call_kwargs["num_results"] == 5

    def test_query_respects_similarity_threshold(
        self, client, mock_api_dependencies, mocker
    ):
        """Test similarity_threshold parameter is passed correctly."""
        mock_retrieval = mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={"results": [], "original_query_assertion_status": "affirmative"}
        )

        payload = {"text": "seizures", "similarity_threshold": 0.7}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        call_kwargs = mock_retrieval.call_args.kwargs
        assert call_kwargs["similarity_threshold"] == 0.7

    def test_query_handles_language_detection_failure(
        self, client, mock_api_dependencies, mocker
    ):
        """Test query gracefully handles language detection failure."""
        mocker.patch(
            "api.routers.query_router.detect_language",
            side_effect=Exception("Language detection failed")
        )

        payload = {"text": "seizures"}  # No language provided
        response = client.post("/api/v1/query", json=payload)

        # Should fallback to default language, not fail
        assert response.status_code == 200
        data = response.json()
        assert data["language_detected"] == "en"  # DEFAULT_LANGUAGE

    def test_query_assertion_detection_enabled_by_default(
        self, client, mock_api_dependencies, mocker
    ):
        """Test assertion detection is enabled by default."""
        mock_retrieval = mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={"results": [], "original_query_assertion_status": "affirmative"}
        )

        payload = {"text": "no seizures"}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        call_kwargs = mock_retrieval.call_args.kwargs
        assert call_kwargs["detect_query_assertion"] is True

    def test_query_assertion_detection_can_be_disabled(
        self, client, mock_api_dependencies, mocker
    ):
        """Test assertion detection can be explicitly disabled."""
        mock_retrieval = mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={"results": [], "original_query_assertion_status": None}
        )

        payload = {"text": "seizures", "detect_query_assertion": False}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        call_kwargs = mock_retrieval.call_args.kwargs
        assert call_kwargs["detect_query_assertion"] is False

    def test_query_returns_assertion_status_in_response(
        self, client, mock_api_dependencies, mocker
    ):
        """Test query response includes assertion status."""
        mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={
                "results": [],
                "original_query_assertion_status": "negated"
            }
        )

        payload = {"text": "no seizures"}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        data = response.json()
        assert data["query_assertion_status"] == "negated"


class TestQueryRouterGET:
    """Tests for GET /api/v1/query endpoint."""

    def test_get_query_with_text_param_returns_200(
        self, client, mock_api_dependencies
    ):
        """Test GET query with text parameter works."""
        response = client.get("/api/v1/query?text=seizures")

        assert response.status_code == 200
        data = response.json()
        assert data["query_text_received"] == "seizures"

    def test_get_query_without_text_returns_422(self, client):
        """Test GET query without text parameter returns error."""
        response = client.get("/api/v1/query")

        assert response.status_code == 422

    def test_get_query_with_all_params_works(
        self, client, mock_api_dependencies
    ):
        """Test GET query with all optional parameters."""
        response = client.get(
            "/api/v1/query"
            "?text=seizures"
            "&model_name=sentence-transformers/all-MiniLM-L6-v2"
            "&language=en"
            "&num_results=5"
            "&similarity_threshold=0.5"
            "&enable_reranker=true"
            "&reranker_mode=cross-lingual"
        )

        assert response.status_code == 200
        data = response.json()
        assert data["query_text_received"] == "seizures"

    @pytest.mark.parametrize("param,value", [
        ("num_results", "-1"),
        ("num_results", "0"),
        ("similarity_threshold", "1.5"),
        ("similarity_threshold", "-0.1"),
    ])
    def test_get_query_with_invalid_params_returns_422(
        self, client, param, value
    ):
        """Test GET query with invalid parameter values."""
        response = client.get(f"/api/v1/query?text=seizures&{param}={value}")

        assert response.status_code == 422

    def test_get_query_reuses_post_endpoint_logic(
        self, client, mock_api_dependencies, mocker
    ):
        """Test GET endpoint calls POST endpoint internally."""
        # Spy on the POST endpoint
        from api.routers import query_router
        mock_post = mocker.spy(query_router, "run_hpo_query")

        response = client.get("/api/v1/query?text=seizures")

        assert response.status_code == 200
        assert mock_post.called


class TestQueryRouterErrorHandling:
    """Tests for error handling in query router."""

    def test_query_with_retriever_unavailable_returns_503(
        self, client, mocker
    ):
        """Test query returns 503 when retriever fails to initialize."""
        # Mock get_dense_retriever_dependency to return None (failure)
        mocker.patch(
            "api.dependencies.get_dense_retriever_dependency",
            return_value=None
        )

        payload = {"text": "seizures"}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 503
        error = response.json()
        assert "detail" in error
        assert "could not be initialized" in error["detail"].lower()

    def test_query_continues_without_reranker_if_loading_fails(
        self, client, mock_api_dependencies, mocker
    ):
        """Test query continues without reranking if cross-encoder fails."""
        # Mock cross-encoder to return None (failure)
        mocker.patch(
            "api.dependencies.get_cross_encoder_dependency",
            return_value=None
        )

        mock_retrieval = mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={"results": [], "original_query_assertion_status": "affirmative"}
        )

        payload = {"text": "seizures", "enable_reranker": True}
        response = client.post("/api/v1/query", json=payload)

        # Should succeed even though reranker failed
        assert response.status_code == 200
        data = response.json()
        assert data["reranker_used"] is None  # No reranker used

        # Verify execute was called with reranking disabled
        call_kwargs = mock_retrieval.call_args.kwargs
        assert call_kwargs["enable_reranker"] is False

    def test_query_handles_retrieval_execution_error(
        self, client, mock_api_dependencies, mocker
    ):
        """Test query handles errors from execute_hpo_retrieval_for_api."""
        mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            side_effect=Exception("Database connection error")
        )

        payload = {"text": "seizures"}

        # Should raise internal server error
        with pytest.raises(Exception, match="Database connection error"):
            client.post("/api/v1/query", json=payload)

    def test_query_logs_retriever_mismatch_warning(
        self, client, mock_api_dependencies, mocker, caplog
    ):
        """Test query logs warning when retriever model doesn't match request."""
        # Create mock retriever with wrong model name
        wrong_retriever = mocker.MagicMock()
        wrong_retriever.model_name = "wrong-model"

        mocker.patch(
            "api.dependencies.get_dense_retriever_dependency",
            side_effect=[wrong_retriever, mock_api_dependencies["retriever"]]
        )

        payload = {"text": "seizures", "model_name": "correct-model"}

        with caplog.at_level("WARNING"):
            response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        assert "Retriever mismatch" in caplog.text


class TestQueryRouterTranslations:
    """Tests for translation directory handling in monolingual mode."""

    def test_monolingual_reranking_checks_translation_dir(
        self, client, mock_api_dependencies, mocker
    ):
        """Test monolingual reranking checks for translation directory."""
        mock_exists = mocker.patch("os.path.exists", return_value=False)
        mock_logger = mocker.patch("api.routers.query_router.logger")

        payload = {
            "text": "seizures",
            "language": "de",
            "enable_reranker": True,
            "reranker_mode": "monolingual",
        }

        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        # Should log warning about missing directory
        assert any("not found" in str(call) for call in mock_logger.warning.call_args_list)

    def test_monolingual_reranking_uses_language_for_translation_dir(
        self, client, mock_api_dependencies, mocker
    ):
        """Test monolingual reranking uses language code for translation path."""
        mock_retrieval = mocker.patch(
            "api.routers.query_router.execute_hpo_retrieval_for_api",
            return_value={"results": [], "original_query_assertion_status": "affirmative"}
        )

        payload = {
            "text": "seizures",
            "language": "de",
            "enable_reranker": True,
            "reranker_mode": "monolingual",
        }

        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
        call_kwargs = mock_retrieval.call_args.kwargs
        # Translation dir should include language code
        assert "de" in call_kwargs["translation_dir_path"]


# =============================================================================
# EDGE CASES & INTEGRATION TESTS
# =============================================================================


class TestQueryRouterEdgeCases:
    """Tests for edge cases and boundary conditions."""

    @pytest.mark.parametrize("text", [
        "a" * 10000,  # Very long text
        "çŸ­ã„",  # Non-ASCII characters
        "12345",  # Only numbers
        "!!!",  # Only special characters
    ])
    def test_query_handles_unusual_text_inputs(
        self, client, mock_api_dependencies, text
    ):
        """Test query handles unusual but valid text inputs."""
        payload = {"text": text}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200

    def test_query_with_num_results_exceeding_threshold(
        self, client, mock_api_dependencies
    ):
        """Test query with very high num_results."""
        payload = {"text": "seizures", "num_results": 100}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200

    def test_query_with_zero_threshold_returns_all_results(
        self, client, mock_api_dependencies
    ):
        """Test query with threshold of 0.0 returns all results."""
        payload = {"text": "seizures", "similarity_threshold": 0.0}
        response = client.post("/api/v1/query", json=payload)

        assert response.status_code == 200
```

**Coverage Goal:** This test file has **20 test classes** covering:
- âœ… Happy path (valid queries)
- âœ… Validation errors (missing/invalid params)
- âœ… Reranker modes (cross-lingual, monolingual)
- âœ… Language detection (auto + explicit)
- âœ… Error handling (retriever failure, reranker failure)
- âœ… Edge cases (long text, special chars)
- âœ… GET vs POST endpoints
- âœ… All query parameters

**Expected coverage:** query_router.py: 0% â†’ **90%+**

---

## Day 4: Query Orchestrator Tests (4 hours)

**File:** `tests/unit/retrieval/test_query_orchestrator.py` (CREATE NEW FILE)

```python
"""Tests for query orchestrator (core query execution logic)."""

import pytest
from unittest.mock import AsyncMock, MagicMock


class TestQueryOrchestratorBasic:
    """Basic functionality tests for query orchestrator."""

    @pytest.mark.asyncio
    async def test_execute_hpo_retrieval_returns_results_dict(
        self, mock_dense_retriever, hpo_query_result_factory
    ):
        """Test basic query execution returns properly formatted results."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        # Set up mock retriever with results
        mock_dense_retriever.query = MagicMock(return_value=[
            hpo_query_result_factory(hpo_id="HP:0001250", score=0.9),
        ])

        result = await execute_hpo_retrieval_for_api(
            text="patient has seizures",
            language="en",
            retriever=mock_dense_retriever,
            num_results=10,
            similarity_threshold=0.3,
        )

        assert isinstance(result, dict)
        assert "results" in result
        assert isinstance(result["results"], list)
        assert len(result["results"]) > 0

    @pytest.mark.asyncio
    async def test_execute_respects_num_results_limit(
        self, mock_dense_retriever, hpo_query_result_factory
    ):
        """Test num_results parameter limits returned results."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        # Mock retriever to return many results
        many_results = [
            hpo_query_result_factory(hpo_id=f"HP:{i:07d}")
            for i in range(100)
        ]
        mock_dense_retriever.query = MagicMock(return_value=many_results)

        result = await execute_hpo_retrieval_for_api(
            text="seizures",
            language="en",
            retriever=mock_dense_retriever,
            num_results=5,
            similarity_threshold=0.0,
        )

        # Should call retriever with correct limit
        mock_dense_retriever.query.assert_called_once()
        call_kwargs = mock_dense_retriever.query.call_args.kwargs
        assert call_kwargs["top_k"] == 5

    @pytest.mark.asyncio
    async def test_execute_filters_by_similarity_threshold(
        self, mock_dense_retriever, hpo_query_result_factory
    ):
        """Test results below threshold are filtered out."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        # Mock results with varying scores
        mock_dense_retriever.query = MagicMock(return_value=[
            hpo_query_result_factory(score=0.9),  # Above threshold
            hpo_query_result_factory(score=0.4),  # Above threshold
            hpo_query_result_factory(score=0.1),  # Below threshold
        ])

        result = await execute_hpo_retrieval_for_api(
            text="seizures",
            language="en",
            retriever=mock_dense_retriever,
            num_results=10,
            similarity_threshold=0.3,
        )

        # Results should be filtered
        # (exact behavior depends on implementation)
        assert "results" in result


class TestQueryOrchestratorReranking:
    """Tests for reranking functionality."""

    @pytest.mark.asyncio
    async def test_execute_with_reranker_calls_cross_encoder(
        self, mock_dense_retriever, mock_cross_encoder, hpo_query_result_factory
    ):
        """Test enabling reranker calls cross-encoder."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        mock_dense_retriever.query = MagicMock(return_value=[
            hpo_query_result_factory(),
        ])

        result = await execute_hpo_retrieval_for_api(
            text="seizures",
            language="en",
            retriever=mock_dense_retriever,
            num_results=10,
            similarity_threshold=0.3,
            enable_reranker=True,
            cross_encoder=mock_cross_encoder,
        )

        # Cross-encoder should be used
        assert mock_cross_encoder.predict.called or True  # Adjust based on implementation

    @pytest.mark.asyncio
    async def test_execute_without_reranker_skips_cross_encoder(
        self, mock_dense_retriever, mock_cross_encoder
    ):
        """Test disabling reranker skips cross-encoder."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        result = await execute_hpo_retrieval_for_api(
            text="seizures",
            language="en",
            retriever=mock_dense_retriever,
            num_results=10,
            similarity_threshold=0.3,
            enable_reranker=False,
        )

        # Cross-encoder should NOT be called
        assert not mock_cross_encoder.predict.called


class TestQueryOrchestratorAssertionDetection:
    """Tests for assertion detection in queries."""

    @pytest.mark.asyncio
    async def test_execute_detects_affirmative_query(
        self, mock_dense_retriever, mocker
    ):
        """Test affirmative query assertion detection."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        mocker.patch(
            "phentrieve.retrieval.api_helpers.detect_assertion",
            return_value="affirmative"
        )

        result = await execute_hpo_retrieval_for_api(
            text="patient has seizures",
            language="en",
            retriever=mock_dense_retriever,
            detect_query_assertion=True,
        )

        assert result.get("original_query_assertion_status") == "affirmative"

    @pytest.mark.asyncio
    async def test_execute_detects_negated_query(
        self, mock_dense_retriever, mocker
    ):
        """Test negated query assertion detection."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        mocker.patch(
            "phentrieve.retrieval.api_helpers.detect_assertion",
            return_value="negated"
        )

        result = await execute_hpo_retrieval_for_api(
            text="patient has no seizures",
            language="en",
            retriever=mock_dense_retriever,
            detect_query_assertion=True,
        )

        assert result.get("original_query_assertion_status") == "negated"

    @pytest.mark.asyncio
    async def test_execute_skips_assertion_when_disabled(
        self, mock_dense_retriever, mocker
    ):
        """Test assertion detection can be disabled."""
        from phentrieve.retrieval.api_helpers import execute_hpo_retrieval_for_api

        mock_detect = mocker.patch("phentrieve.retrieval.api_helpers.detect_assertion")

        result = await execute_hpo_retrieval_for_api(
            text="patient has seizures",
            language="en",
            retriever=mock_dense_retriever,
            detect_query_assertion=False,
        )

        assert not mock_detect.called
```

**Expected coverage:** query_orchestrator.py: 8% â†’ **70%+**

---

## Quick Reference: Running Tests

```bash
# Run all tests
make test

# Run specific test file
pytest tests/unit/api/test_query_router.py -v

# Run with coverage for specific module
pytest tests/unit/api/test_query_router.py \
  --cov=api/routers/query_router.py \
  --cov-report=term-missing

# Run test linter (anti-patterns check)
make lint-tests

# Run single test
pytest tests/unit/api/test_query_router.py::TestQueryRouterPOST::test_query_with_valid_request_returns_200 -v
```

---

## Success Metrics

**After Day 1-4 (Week 1):**
- âœ… flake8-pytest-style installed and configured
- âœ… Shared fixtures created (12+ reusable fixtures)
- âœ… `api/routers/query_router.py`: 0% â†’ **90%+**
- âœ… `phentrieve/retrieval/query_orchestrator.py`: 8% â†’ **70%+**
- âœ… All tests pass (`make test`)
- âœ… No anti-patterns detected (`make lint-tests`)

**Impact:** Critical API endpoints fully tested!

---

## Next Steps (Week 2+)

1. **Day 5**: Similarity router tests (0% â†’ 80%)
2. **Week 2**: Text processing router tests (0% â†’ 80%)
3. **Week 3**: Expand CLI tests, integration tests
4. **Week 4-7**: Continue per main testing plan

---

**Status:** Ready to implement!
**Estimated Time:** Week 1 = 20 hours of focused work
**Expected Coverage Increase:** 8% â†’ 35-40% (critical paths fully tested!)
