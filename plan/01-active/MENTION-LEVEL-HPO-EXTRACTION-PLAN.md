# Mention-Level HPO Extraction Implementation Plan

**Status:** âœ… Core Implementation Complete
**Created:** 2025-12-13
**Updated:** 2025-12-13
**Branch:** `feat/graph-based-146`
**Priority:** High
**Estimated Effort:** 2-3 weeks implementation

---

## Progress Summary

### âœ… Completed (Phase 1-8)

| Component | File | Status |
|-----------|------|--------|
| Core dataclasses | `mention.py` | âœ… Complete |
| Document structure | `document_structure.py` | âœ… Complete |
| Mention extraction | `mention_extractor.py` | âœ… Complete |
| Assertion detection | `mention_assertion.py` | âœ… Complete |
| HPO retrieval | `mention_hpo_retriever.py` | âœ… Complete |
| Candidate refinement | `mention_candidate_refiner.py` | âœ… Complete |
| Context propagation | `mention_context.py` | âœ… Complete |
| Mention grouping | `mention_grouper.py` | âœ… Complete |
| Document aggregation | `mention_aggregator.py` | âœ… Complete |
| Orchestrator | `mention_extraction_orchestrator.py` | âœ… Complete |
| Unit tests | 3 test files | âœ… Complete |
| Type checking | mypy | âœ… 0 errors |
| Linting | ruff | âœ… All checks passed |

### ğŸ”„ Remaining Work

- [ ] Integration tests with real DenseRetriever
- [ ] CLI integration 
- [ ] Benchmark evaluation against ID-68, GSC+, GeneReviews
- [ ] Performance optimization (batch processing tuning)
- [ ] Documentation updates

---

## Executive Summary

This plan implements a mention-level HPO extraction system that:
- Extracts clinically relevant HPO terms with dataset-specific assertion labels at the document level
- Uses mention-level representations internally for improved accuracy across chunk boundaries
- Reduces overly generic HPO mappings through specificity control
- Supports grouping of alternative explanations for the same clinical finding
- Maintains full compatibility with existing benchmarks (ID-68, GSC+, GeneReviews)

---

## Architecture Overview

### Core Principle: Separation of Concerns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Document Input                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage A: Structural Scaffolding                                             â”‚
â”‚  â”œâ”€â”€ Sentence segmentation                                                   â”‚
â”‚  â”œâ”€â”€ Lightweight section detection                                           â”‚
â”‚  â””â”€â”€ Context boundary markers (e.g., family history regions)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage B: Mention Discovery                                                  â”‚
â”‚  â”œâ”€â”€ Identify candidate clinical finding spans                               â”‚
â”‚  â”œâ”€â”€ NP/VP extraction with semantic filtering                                â”‚
â”‚  â””â”€â”€ Create Mention objects with span information                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage C: Assertion Interpretation                                           â”‚
â”‚  â”œâ”€â”€ Per-mention assertion using canonical labels                            â”‚
â”‚  â”œâ”€â”€ Scope-aware detection (ConText-based)                                   â”‚
â”‚  â””â”€â”€ Confidence scores for soft decisions                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage D: HPO Candidate Generation                                           â”‚
â”‚  â”œâ”€â”€ Dense retrieval per mention                                             â”‚
â”‚  â”œâ”€â”€ High-recall candidate set (10-20 candidates)                            â”‚
â”‚  â””â”€â”€ Preserve local semantic context                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage E: Candidate Refinement & Specificity Control                         â”‚
â”‚  â”œâ”€â”€ Cross-encoder re-ranking with mention context                           â”‚
â”‚  â”œâ”€â”€ Ontology-aware specificity scoring                                      â”‚
â”‚  â””â”€â”€ Disfavor generic terms when specific alternatives exist                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage F: Controlled Contextual Influence                                    â”‚
â”‚  â”œâ”€â”€ Limited cross-mention context propagation                               â”‚
â”‚  â”œâ”€â”€ Gated by proximity and document region                                  â”‚
â”‚  â””â”€â”€ Optional graph-based refinement layer                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage G: Content-Based Grouping                                             â”‚
â”‚  â”œâ”€â”€ Cluster mentions referring to same phenomenon                           â”‚
â”‚  â”œâ”€â”€ Rank alternative HPO explanations per group                             â”‚
â”‚  â””â”€â”€ Soft signals: textual similarity, proximity, ontology structure         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage H: Document-Level Aggregation                                         â”‚
â”‚  â”œâ”€â”€ Aggregate groups to document-level HPO set                              â”‚
â”‚  â”œâ”€â”€ Apply dataset-specific assertion label mapping                          â”‚
â”‚  â””â”€â”€ Handle conflicts transparently                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Benchmark-Compatible Output                          â”‚
â”‚  â”œâ”€â”€ Document-level HPO set with assertions                                  â”‚
â”‚  â”œâ”€â”€ Optional: mention-level details for analysis                            â”‚
â”‚  â””â”€â”€ Evaluable against ID-68, GSC+, GeneReviews                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Phases

### Phase 1: Core Data Structures (Days 1-2)

**Goal:** Define mention-level representations and grouping structures.

#### 1.1 Mention Dataclass

**File:** `phentrieve/text_processing/mention.py`

```python
@dataclass
class Mention:
    """A clinical finding mention in text with span and semantic info."""
    mention_id: str                      # Unique identifier
    text: str                            # Surface text
    start_char: int                      # Start position in document
    end_char: int                        # End position in document
    sentence_idx: int                    # Sentence index
    section_type: str | None             # Section context (e.g., "family_history")
    embedding: np.ndarray | None         # Computed embedding
    assertion: AssertionVector           # Multi-dimensional assertion
    hpo_candidates: list[HPOCandidate]   # Ranked HPO candidates
    metadata: dict[str, Any]             # Extensibility (future: time, anatomy)
```

#### 1.2 HPO Candidate Dataclass

```python
@dataclass  
class HPOCandidate:
    """A candidate HPO term for a mention."""
    hpo_id: str
    label: str
    score: float                         # Initial retrieval score
    refined_score: float | None          # After re-ranking
    specificity_score: float             # Ontology depth-based
    is_generic: bool                     # Flag for generic terms
```

#### 1.3 Mention Group Dataclass

```python
@dataclass
class MentionGroup:
    """Group of mentions referring to the same clinical phenomenon."""
    group_id: str
    mentions: list[Mention]
    representative_mention: Mention      # Best exemplar
    ranked_hpo_explanations: list[HPOCandidate]  # Merged and ranked
    final_hpo: HPOCandidate | None       # Selected for output
    final_assertion: AssertionVector     # Aggregated assertion
```

### Phase 2: Structural Scaffolding (Day 3)

**Goal:** Lightweight sentence/section detection for context gating.

#### 2.1 Document Structure Detector

**File:** `phentrieve/text_processing/document_structure.py`

- Sentence segmentation using spaCy
- Section header detection (regex + keyword-based)
- Family history region detection (reuse existing `family_history_processor.py`)
- Output: `DocumentStructure` with sentences and section boundaries

### Phase 3: Mention Discovery (Days 4-5)

**Goal:** Identify candidate clinical finding spans.

#### 3.1 Mention Extractor

**File:** `phentrieve/text_processing/mention_extractor.py`

- Use spaCy noun phrase extraction as base
- Apply clinical finding filters (exclude pronouns, stopwords)
- Optionally use dependency patterns for finding descriptions
- Generate `Mention` objects with spans

### Phase 4: Assertion Interpretation (Day 6)

**Goal:** Per-mention assertion detection with canonical labels.

#### 4.1 Mention Assertion Detector

**File:** `phentrieve/text_processing/mention_assertion.py`

- Reuse existing `AssertionDetector` but at mention-level
- Create `AssertionVector` for each mention
- Scope-aware: use mention span, not full chunk
- Map to canonical internal labels

### Phase 5: HPO Candidate Generation (Days 7-8)

**Goal:** Dense retrieval per mention for high-recall candidate sets.

#### 5.1 Mention HPO Retriever

**File:** `phentrieve/text_processing/mention_hpo_retriever.py`

- Batch embed all mentions
- Query retriever with mention text + local context
- Return top-K candidates per mention (K=10-20)
- Preserve similarity scores

### Phase 6: Candidate Refinement (Days 9-10)

**Goal:** Re-rank and apply specificity control.

#### 6.1 Mention Candidate Refiner

**File:** `phentrieve/text_processing/mention_candidate_refiner.py`

- Cross-encoder re-ranking with mention context
- Ontology depth-based specificity scoring
- Soft penalty for generic terms when specific alternatives exist
- Output refined scores

### Phase 7: Controlled Context & Grouping (Days 11-12)

**Goal:** Cross-mention context and phenomenon grouping.

#### 7.1 Context Propagator

**File:** `phentrieve/text_processing/mention_context.py`

- Build mention graph (adjacency, similarity-based edges)
- Gated context influence (same section, proximity constraints)
- Integrate with existing `SemanticDocumentGraph`

#### 7.2 Mention Grouper

**File:** `phentrieve/text_processing/mention_grouper.py`

- Cluster mentions by textual similarity + HPO overlap
- Create `MentionGroup` objects
- Rank alternative HPO explanations per group

### Phase 8: Document-Level Aggregation (Days 13-14)

**Goal:** Produce benchmark-compatible output.

#### 8.1 Document Aggregator

**File:** `phentrieve/text_processing/mention_aggregator.py`

- Aggregate groups to document-level HPO set
- Apply dataset-specific assertion mapping
- Handle conflicts (multiple assertions for same HPO)
- Produce output compatible with existing benchmark format

### Phase 9: Orchestrator Integration (Day 15)

**Goal:** Integrate with existing pipeline.

#### 9.1 Mention-Based Orchestrator

**File:** `phentrieve/text_processing/mention_extraction_orchestrator.py`

- New orchestrator that uses mention-level processing
- Drop-in replacement for `orchestrate_hpo_extraction` with same interface
- Configuration flag to switch between chunk-based and mention-based

### Phase 10: Benchmark Integration & Validation (Days 16-17)

**Goal:** Validate against existing benchmarks.

- Run on ID-68, GSC+, GeneReviews with unchanged scoring
- Compare to chunk-based baseline
- Ablation studies (with/without mention-level, context, grouping)

---

## File Structure

```
phentrieve/text_processing/
â”œâ”€â”€ mention.py                       # Core mention dataclasses (NEW)
â”œâ”€â”€ mention_extractor.py             # Mention discovery (NEW)
â”œâ”€â”€ mention_assertion.py             # Per-mention assertion (NEW)
â”œâ”€â”€ mention_hpo_retriever.py         # Mention-level HPO retrieval (NEW)
â”œâ”€â”€ mention_candidate_refiner.py     # Refinement & specificity (NEW)
â”œâ”€â”€ mention_context.py               # Context propagation (NEW)
â”œâ”€â”€ mention_grouper.py               # Phenomenon grouping (NEW)
â”œâ”€â”€ mention_aggregator.py            # Document-level output (NEW)
â”œâ”€â”€ mention_extraction_orchestrator.py # Main orchestrator (NEW)
â”œâ”€â”€ document_structure.py            # Sentence/section detection (NEW)
â”œâ”€â”€ assertion_detection.py           # (EXISTING - reused)
â”œâ”€â”€ assertion_representation.py      # (EXISTING - reused)
â”œâ”€â”€ semantic_graph.py                # (EXISTING - integrated)
â”œâ”€â”€ hpo_extraction_orchestrator.py   # (EXISTING - preserved)
â””â”€â”€ pipeline.py                      # (EXISTING - add config option)
```

---

## Configuration

Add to `phentrieve.yaml.template`:

```yaml
mention_extraction:
  enabled: true
  # Mention discovery
  min_mention_length: 2
  max_mention_length: 50
  # HPO candidate generation
  candidates_per_mention: 15
  retrieval_threshold: 0.25
  # Specificity control
  enable_specificity_scoring: true
  generic_term_penalty: 0.1
  min_specificity_depth: 3
  # Context propagation
  enable_context_propagation: true
  context_radius: 2
  same_section_only: true
  # Grouping
  enable_grouping: true
  grouping_similarity_threshold: 0.7
  grouping_hpo_overlap_threshold: 0.5
  # Output
  output_top_n_per_group: 3
  include_mention_details: false
```

---

## Assertion Label Mapping

### Internal Canonical Labels

```python
class CanonicalAssertion(Enum):
    AFFIRMED = "affirmed"      # Finding is present
    NEGATED = "negated"        # Finding is absent
    UNCERTAIN = "uncertain"    # Epistemic uncertainty
    NORMAL = "normal"          # Within normal limits
    HISTORICAL = "historical"  # Past finding
    FAMILY = "family"          # Family member finding
```

### Dataset-Specific Mappings

```python
DATASET_ASSERTION_MAPS = {
    "phenobert": {
        "AFFIRMED": "PRESENT",
        "NEGATED": "ABSENT",
        "UNCERTAIN": "UNCERTAIN",
        "NORMAL": "PRESENT",  # Normal is still a present finding
        "HISTORICAL": "PRESENT",
        "FAMILY": "PRESENT",  # Tracked separately
    },
    "gsc_plus": {
        # Same as phenobert for now
    },
    # Extensible for future datasets
}
```

---

## Integration with Existing Graph Approach

The existing `SemanticDocumentGraph` integrates naturally:

1. **Nodes**: `ChunkNode` â†’ `MentionNode` (or wrap mentions in chunks)
2. **Edges**: 
   - Sequential edges â†’ mention adjacency
   - Semantic edges â†’ mention similarity
   - HPO coreference edges â†’ same HPO candidate edges
3. **Propagation**: `AssertionPropagator` works at mention level
4. **Consistency**: Ontology checks at aggregation stage

---

## Validation Strategy

### Primary Validation
- Run unchanged benchmark scoring on ID-68, GSC+, GeneReviews
- Compare document-level F1, precision, recall to chunk-based baseline

### Ablation Studies
- With/without mention-level mapping
- With/without context propagation
- With/without grouping
- With/without specificity control

### Proxy Metrics
- Redundancy rate (duplicate HPO assignments)
- Generic term prevalence (proportion of shallow HPO terms)
- Context leakage rate (family history terms on patient)

---

## Testing Strategy

### Unit Tests

```
tests/unit/text_processing/
â”œâ”€â”€ test_mention.py                  # Mention dataclass tests
â”œâ”€â”€ test_mention_extractor.py        # Extraction tests
â”œâ”€â”€ test_mention_assertion.py        # Assertion tests
â”œâ”€â”€ test_mention_hpo_retriever.py    # Retrieval tests
â”œâ”€â”€ test_mention_candidate_refiner.py
â”œâ”€â”€ test_mention_context.py
â”œâ”€â”€ test_mention_grouper.py
â”œâ”€â”€ test_mention_aggregator.py
â””â”€â”€ test_mention_extraction_orchestrator.py
```

### Integration Tests

- Full pipeline test with sample documents
- Comparison with chunk-based orchestrator
- Benchmark evaluation tests

---

## Next Steps

1. **Immediate**: Create `mention.py` with core dataclasses
2. **Day 1-2**: Implement `Mention`, `HPOCandidate`, `MentionGroup`
3. **Day 3**: Implement `DocumentStructure` detector
4. **Day 4-5**: Implement `MentionExtractor`
5. **Continue**: Follow phase sequence above

---

## Related Issues

- **Primary**: Graph-based assertion extension (#146)
- **Related**: Full-text HPO extraction benchmark (#17)
- **Related**: Assertion detection improvements (#126)
